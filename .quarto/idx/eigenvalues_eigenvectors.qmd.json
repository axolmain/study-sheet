{"title":"Eigenvalues and Eigenvectors in Linear Algebra","markdown":{"yaml":{"title":"Eigenvalues and Eigenvectors in Linear Algebra","format":{"html":{"toc":true,"toc-depth":3,"number-sections":true,"html-math-method":"katex"}}},"headingText":"Eigenvalues and Eigenvectors in Linear Algebra","containsRefs":false,"markdown":"\n\n\n## Introduction\n\nEigenvalues and eigenvectors are fundamental concepts in linear algebra that help us understand how linear transformations affect vector spaces. They are particularly useful in analyzing linear operators and their behavior on invariant subspaces.\n\nI'll expand your request with collapsible example sections for each concept, showing detailed step-by-step calculations.\n\n## Key Concepts and Definitions\n\n### Eigenvalues\n::: {.callout-note}\n**Definition**: A scalar $\\lambda \\in \\mathbb{R}$ is called an eigenvalue of operator $T: V \\to V$ if there exists a nonzero vector $\\mathbf{u} \\in V$ such that $T\\mathbf{u} = \\lambda\\mathbf{u}$.\n:::\n\n<details>\n<summary>Example: Finding Eigenvalues</summary>\n\nLet's find the eigenvalues of matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$\n\n1) Set up characteristic equation: $det(A - \\lambda I) = 0$\n\n2) Expand determinant:\n   $$det\\begin{bmatrix} 3-\\lambda & 1 \\\\ 1 & 3-\\lambda \\end{bmatrix} = 0$$\n   $$(3-\\lambda)(3-\\lambda) - (1)(1) = 0$$\n\n3) Solve polynomial:\n   $$\\lambda^2 - 6\\lambda + 8 = 0$$\n   $$(\\lambda - 4)(\\lambda - 2) = 0$$\n   $$\\lambda = 4 \\text{ or } \\lambda = 2$$\n\nTherefore, the eigenvalues are $\\lambda_1 = 4$ and $\\lambda_2 = 2$\n</details>\n\n### Eigenvectors\n::: {.callout-note}\n**Definition**: For an eigenvalue $\\lambda$ of matrix $A$, a vector $\\mathbf{x} \\in V$ is called an eigenvector of $A$ (corresponding to $\\lambda$) if $A\\mathbf{x} = \\lambda\\mathbf{x}$.\n:::\n\n<details>\n<summary>Example: Finding Eigenvectors</summary>\n\nUsing the same matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$ and $\\lambda_1 = 4$:\n\n1) Set up equation $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$:\n   $$\\begin{bmatrix} 3-4 & 1 \\\\ 1 & 3-4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n2) Simplify system of equations:\n   $$\\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n3) Solve system:\n   $$-x_1 + x_2 = 0$$\n   $$x_1 = x_2$$\n\n4) Choose a non-zero solution:\n   Let $x_1 = 1$, then $x_2 = 1$\n   \nTherefore, $\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ is an eigenvector for $\\lambda_1 = 4$\n</details>\n\n### Eigenspace\n::: {.callout-note}\n**Definition**: The eigenspace of matrix $A$ corresponding to eigenvalue $\\lambda$ is the set of all solutions to $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$, which is equivalent to $\\text{Nul}(A - \\lambda I)$.\n:::\n\n<details>\n<summary>Example: Finding Eigenspace</summary>\n\nFor the same matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$ and $\\lambda_1 = 4$:\n\n1) Form $A - \\lambda I$:\n   $$A - 4I = \\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix}$$\n\n2) Find general solution to $(A - 4I)\\mathbf{x} = \\mathbf{0}$:\n   $$\\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n3) Row reduce to find basis:\n   - From earlier, we found $x_1 = x_2$\n   - Let $t$ be a free parameter\n\n4) Express eigenspace:\n   $$E_4 = \\text{span}\\left\\{\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\right\\}$$\n   $$= \\left\\{t\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} : t \\in \\mathbb{R}\\right\\}$$\n\nThis is the complete eigenspace corresponding to $\\lambda_1 = 4$\n</details>\n\n## Important Theorems\n\n### Theorem 1: Eigenvalues of Triangular Matrices\n**Statement**: The eigenvalues of a triangular matrix are the entries on its main diagonal.\n\n::: {.callout-note}\n#### Proof\nLet $T: V \\to V$ have an upper-triangular matrix $A$ with respect to some basis $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}$:\n\n$$A = \\begin{bmatrix} \n\\lambda_1 & * & \\cdots & * \\\\\n0 & \\lambda_2 & \\cdots & * \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_n\n\\end{bmatrix}$$\n\nFor any $\\lambda \\in \\mathbb{R}$, $A - \\lambda I$ has the form:\n$$A - \\lambda I = \\begin{bmatrix} \n\\lambda_1 - \\lambda & * & \\cdots & * \\\\\n0 & \\lambda_2 - \\lambda & \\cdots & * \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_n - \\lambda\n\\end{bmatrix}$$\n\n$A - \\lambda I$ is not invertible if and only if $\\lambda$ equals one of the $\\lambda_i$'s (since $\\det(A - \\lambda I) = \\prod_{i=1}^n (\\lambda_i - \\lambda)$).\nTherefore, $\\lambda$ is an eigenvalue of $T$ if and only if $\\lambda$ equals one of the diagonal entries $\\lambda_i$.\n:::\n\n### Theorem 2: Linear Independence of Eigenvectors\n**Statement**: If $\\mathbf{v}_1, \\ldots, \\mathbf{v}_r$ are eigenvectors that correspond to distinct eigenvalues $\\lambda_1, \\ldots, \\lambda_r$ of an $n \\times n$ matrix $A$, then the set $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ is linearly independent.\n\n::: {.callout-note}\n#### Proof\n1. Assume by contradiction that $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ is linearly dependent\n2. Let $k$ be smallest positive integer such that $\\mathbf{v}_k \\in \\text{Span}\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_{k-1}\\}$\n3. Then there exist scalars $a_1, \\ldots, a_{k-1}$ such that:\n   $\\mathbf{v}_k = a_1\\mathbf{v}_1 + \\cdots + a_{k-1}\\mathbf{v}_{k-1}$\n4. Apply $A$ to both sides:\n   $\\lambda_k\\mathbf{v}_k = a_1\\lambda_1\\mathbf{v}_1 + \\cdots + a_{k-1}\\lambda_{k-1}\\mathbf{v}_{k-1}$\n5. Multiply original equation by $\\lambda_k$ and subtract:\n   $\\mathbf{0} = a_1(\\lambda_k - \\lambda_1)\\mathbf{v}_1 + \\cdots + a_{k-1}(\\lambda_k - \\lambda_{k-1})\\mathbf{v}_{k-1}$\n6. Since $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_{k-1}\\}$ is linearly independent and $\\lambda_k \\neq \\lambda_i$ for $i < k$, all $a_i$ must be 0\n7. This implies $\\mathbf{v}_k = \\mathbf{0}$, contradicting that $\\mathbf{v}_k$ is an eigenvector\nTherefore, $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ must be linearly independent\n:::\n\n## Practice Problems\n\n### Problem 1: Zero Eigenvalue\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nWhat does it mean for a matrix $A$ to have an eigenvalue of 0?\n\n#### Solution\nFor $\\lambda = 0$ to be an eigenvalue of $A$:\n\n1. There must exist a nonzero vector $\\mathbf{x}$ such that $A\\mathbf{x} = 0\\mathbf{x} = \\mathbf{0}$\n2. This means $\\mathbf{x} \\in \\text{Nul}(A)$, and $\\mathbf{x} \\neq \\mathbf{0}$\n3. Therefore, $A$ having an eigenvalue of 0 means:\n   - $A$ is not invertible\n   - $A$ has a nontrivial null space\n   - $\\det(A) = 0$\n   - $A$ is singular\n\nExample:\nConsider $A = \\begin{bmatrix} 1 & 2 \\\\ -2 & -4 \\end{bmatrix}$\n- $\\det(A) = 1(-4) - 2(-2) = -4 + 4 = 0$\n- The vector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$ is in $\\text{Nul}(A)$\n- Therefore, 0 is an eigenvalue with eigenvector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$\n:::\n\n### Problem 2: First-Order Difference Equations\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nGiven a first-order difference equation $\\mathbf{x}_{k+1} = A\\mathbf{x}_k$, where $A$ is an $n\\times n$ matrix, explain how to construct solutions.\n\n#### Solution\n1. Find eigenvalues $\\lambda_i$ and corresponding eigenvectors $\\mathbf{v}_i$ of $A$\n2. Any solution has the form:\n   $\\mathbf{x}_k = c_1\\lambda_1^k\\mathbf{v}_1 + c_2\\lambda_2^k\\mathbf{v}_2 + \\cdots + c_n\\lambda_n^k\\mathbf{v}_n$\n   where $c_i$ are constants determined by initial conditions\n\nExample:\nFor $A = \\begin{bmatrix} 2 & 1 \\\\ -1 & 4 \\end{bmatrix}$, let's find solution with $\\mathbf{x}_0 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$:\n1. Find eigenvalues: $\\lambda = 3,1$\n2. Find eigenvectors: $\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, $\\mathbf{v}_2 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n3. Write $\\mathbf{x}_0 = c_1\\mathbf{v}_1 + c_2\\mathbf{v}_2$\n4. Solve for $c_i$: $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = c_1\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + c_2\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n5. Get $c_1 = \\frac{1}{2}$, $c_2 = \\frac{1}{2}$\n6. Solution: $\\mathbf{x}_k = \\frac{1}{2}(3^k)\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\frac{1}{2}(1^k)\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n:::\n\n### Problem 3: Determining if λ is an Eigenvalue\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nDetermine if $\\lambda = 2$ is an eigenvalue of $A = \\begin{bmatrix} 3 & 1 \\\\ -1 & 5 \\end{bmatrix}$\n\n#### Solution\nStep 1: Form $A - 2I$\n$$A - 2I = \\begin{bmatrix} 1 & 1 \\\\ -1 & 3 \\end{bmatrix}$$\n\nStep 2: Calculate $\\det(A - 2I)$\n$\\det(A - 2I) = (1)(3) - (1)(-1) = 3 + 1 = 4$\n\nStep 3: Conclusion\nSince $\\det(A - 2I) \\neq 0$, $\\lambda = 2$ is not an eigenvalue of $A$\n\nAlternative method:\n1. Find characteristic equation: $\\det(A - \\lambda I) = 0$\n2. $(3-\\lambda)(5-\\lambda) - (-1)(1) = 0$\n3. $\\lambda^2 - 8\\lambda + 14 = 0$\n4. $\\lambda = 4 \\pm \\sqrt{2}$\nTherefore, 2 is not an eigenvalue\n:::\n\n## Common Mistakes to Avoid\n\n1. Not checking if eigenvector is nonzero\n2. Assuming eigenvalues must be on the main diagonal (only true for triangular matrices)\n3. Forgetting that eigenvectors corresponding to the same eigenvalue might be linearly dependent\n4. Not verifying that λ is a real number when working in real vector spaces\n5. Confusing eigenspace with the span of eigenvectors\n\n## Additional Resources\n\n- [3Blue1Brown - Essence of Linear Algebra (YouTube)](https://www.youtube.com/watch?v=kjBOesZCoqc)\n- Gilbert Strang's Linear Algebra Lectures (MIT OpenCourseWare)\n- \"Introduction to Probability\" by Bertsekas and Tsitsiklis\n- \"Matrix Analysis\" by Horn and Johnson","srcMarkdownNoYaml":"\n\n# Eigenvalues and Eigenvectors in Linear Algebra\n\n## Introduction\n\nEigenvalues and eigenvectors are fundamental concepts in linear algebra that help us understand how linear transformations affect vector spaces. They are particularly useful in analyzing linear operators and their behavior on invariant subspaces.\n\nI'll expand your request with collapsible example sections for each concept, showing detailed step-by-step calculations.\n\n## Key Concepts and Definitions\n\n### Eigenvalues\n::: {.callout-note}\n**Definition**: A scalar $\\lambda \\in \\mathbb{R}$ is called an eigenvalue of operator $T: V \\to V$ if there exists a nonzero vector $\\mathbf{u} \\in V$ such that $T\\mathbf{u} = \\lambda\\mathbf{u}$.\n:::\n\n<details>\n<summary>Example: Finding Eigenvalues</summary>\n\nLet's find the eigenvalues of matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$\n\n1) Set up characteristic equation: $det(A - \\lambda I) = 0$\n\n2) Expand determinant:\n   $$det\\begin{bmatrix} 3-\\lambda & 1 \\\\ 1 & 3-\\lambda \\end{bmatrix} = 0$$\n   $$(3-\\lambda)(3-\\lambda) - (1)(1) = 0$$\n\n3) Solve polynomial:\n   $$\\lambda^2 - 6\\lambda + 8 = 0$$\n   $$(\\lambda - 4)(\\lambda - 2) = 0$$\n   $$\\lambda = 4 \\text{ or } \\lambda = 2$$\n\nTherefore, the eigenvalues are $\\lambda_1 = 4$ and $\\lambda_2 = 2$\n</details>\n\n### Eigenvectors\n::: {.callout-note}\n**Definition**: For an eigenvalue $\\lambda$ of matrix $A$, a vector $\\mathbf{x} \\in V$ is called an eigenvector of $A$ (corresponding to $\\lambda$) if $A\\mathbf{x} = \\lambda\\mathbf{x}$.\n:::\n\n<details>\n<summary>Example: Finding Eigenvectors</summary>\n\nUsing the same matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$ and $\\lambda_1 = 4$:\n\n1) Set up equation $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$:\n   $$\\begin{bmatrix} 3-4 & 1 \\\\ 1 & 3-4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n2) Simplify system of equations:\n   $$\\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n3) Solve system:\n   $$-x_1 + x_2 = 0$$\n   $$x_1 = x_2$$\n\n4) Choose a non-zero solution:\n   Let $x_1 = 1$, then $x_2 = 1$\n   \nTherefore, $\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ is an eigenvector for $\\lambda_1 = 4$\n</details>\n\n### Eigenspace\n::: {.callout-note}\n**Definition**: The eigenspace of matrix $A$ corresponding to eigenvalue $\\lambda$ is the set of all solutions to $(A - \\lambda I)\\mathbf{x} = \\mathbf{0}$, which is equivalent to $\\text{Nul}(A - \\lambda I)$.\n:::\n\n<details>\n<summary>Example: Finding Eigenspace</summary>\n\nFor the same matrix $A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}$ and $\\lambda_1 = 4$:\n\n1) Form $A - \\lambda I$:\n   $$A - 4I = \\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix}$$\n\n2) Find general solution to $(A - 4I)\\mathbf{x} = \\mathbf{0}$:\n   $$\\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n\n3) Row reduce to find basis:\n   - From earlier, we found $x_1 = x_2$\n   - Let $t$ be a free parameter\n\n4) Express eigenspace:\n   $$E_4 = \\text{span}\\left\\{\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\right\\}$$\n   $$= \\left\\{t\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} : t \\in \\mathbb{R}\\right\\}$$\n\nThis is the complete eigenspace corresponding to $\\lambda_1 = 4$\n</details>\n\n## Important Theorems\n\n### Theorem 1: Eigenvalues of Triangular Matrices\n**Statement**: The eigenvalues of a triangular matrix are the entries on its main diagonal.\n\n::: {.callout-note}\n#### Proof\nLet $T: V \\to V$ have an upper-triangular matrix $A$ with respect to some basis $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}$:\n\n$$A = \\begin{bmatrix} \n\\lambda_1 & * & \\cdots & * \\\\\n0 & \\lambda_2 & \\cdots & * \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_n\n\\end{bmatrix}$$\n\nFor any $\\lambda \\in \\mathbb{R}$, $A - \\lambda I$ has the form:\n$$A - \\lambda I = \\begin{bmatrix} \n\\lambda_1 - \\lambda & * & \\cdots & * \\\\\n0 & \\lambda_2 - \\lambda & \\cdots & * \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_n - \\lambda\n\\end{bmatrix}$$\n\n$A - \\lambda I$ is not invertible if and only if $\\lambda$ equals one of the $\\lambda_i$'s (since $\\det(A - \\lambda I) = \\prod_{i=1}^n (\\lambda_i - \\lambda)$).\nTherefore, $\\lambda$ is an eigenvalue of $T$ if and only if $\\lambda$ equals one of the diagonal entries $\\lambda_i$.\n:::\n\n### Theorem 2: Linear Independence of Eigenvectors\n**Statement**: If $\\mathbf{v}_1, \\ldots, \\mathbf{v}_r$ are eigenvectors that correspond to distinct eigenvalues $\\lambda_1, \\ldots, \\lambda_r$ of an $n \\times n$ matrix $A$, then the set $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ is linearly independent.\n\n::: {.callout-note}\n#### Proof\n1. Assume by contradiction that $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ is linearly dependent\n2. Let $k$ be smallest positive integer such that $\\mathbf{v}_k \\in \\text{Span}\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_{k-1}\\}$\n3. Then there exist scalars $a_1, \\ldots, a_{k-1}$ such that:\n   $\\mathbf{v}_k = a_1\\mathbf{v}_1 + \\cdots + a_{k-1}\\mathbf{v}_{k-1}$\n4. Apply $A$ to both sides:\n   $\\lambda_k\\mathbf{v}_k = a_1\\lambda_1\\mathbf{v}_1 + \\cdots + a_{k-1}\\lambda_{k-1}\\mathbf{v}_{k-1}$\n5. Multiply original equation by $\\lambda_k$ and subtract:\n   $\\mathbf{0} = a_1(\\lambda_k - \\lambda_1)\\mathbf{v}_1 + \\cdots + a_{k-1}(\\lambda_k - \\lambda_{k-1})\\mathbf{v}_{k-1}$\n6. Since $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_{k-1}\\}$ is linearly independent and $\\lambda_k \\neq \\lambda_i$ for $i < k$, all $a_i$ must be 0\n7. This implies $\\mathbf{v}_k = \\mathbf{0}$, contradicting that $\\mathbf{v}_k$ is an eigenvector\nTherefore, $\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_r\\}$ must be linearly independent\n:::\n\n## Practice Problems\n\n### Problem 1: Zero Eigenvalue\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nWhat does it mean for a matrix $A$ to have an eigenvalue of 0?\n\n#### Solution\nFor $\\lambda = 0$ to be an eigenvalue of $A$:\n\n1. There must exist a nonzero vector $\\mathbf{x}$ such that $A\\mathbf{x} = 0\\mathbf{x} = \\mathbf{0}$\n2. This means $\\mathbf{x} \\in \\text{Nul}(A)$, and $\\mathbf{x} \\neq \\mathbf{0}$\n3. Therefore, $A$ having an eigenvalue of 0 means:\n   - $A$ is not invertible\n   - $A$ has a nontrivial null space\n   - $\\det(A) = 0$\n   - $A$ is singular\n\nExample:\nConsider $A = \\begin{bmatrix} 1 & 2 \\\\ -2 & -4 \\end{bmatrix}$\n- $\\det(A) = 1(-4) - 2(-2) = -4 + 4 = 0$\n- The vector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$ is in $\\text{Nul}(A)$\n- Therefore, 0 is an eigenvalue with eigenvector $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$\n:::\n\n### Problem 2: First-Order Difference Equations\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nGiven a first-order difference equation $\\mathbf{x}_{k+1} = A\\mathbf{x}_k$, where $A$ is an $n\\times n$ matrix, explain how to construct solutions.\n\n#### Solution\n1. Find eigenvalues $\\lambda_i$ and corresponding eigenvectors $\\mathbf{v}_i$ of $A$\n2. Any solution has the form:\n   $\\mathbf{x}_k = c_1\\lambda_1^k\\mathbf{v}_1 + c_2\\lambda_2^k\\mathbf{v}_2 + \\cdots + c_n\\lambda_n^k\\mathbf{v}_n$\n   where $c_i$ are constants determined by initial conditions\n\nExample:\nFor $A = \\begin{bmatrix} 2 & 1 \\\\ -1 & 4 \\end{bmatrix}$, let's find solution with $\\mathbf{x}_0 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$:\n1. Find eigenvalues: $\\lambda = 3,1$\n2. Find eigenvectors: $\\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, $\\mathbf{v}_2 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n3. Write $\\mathbf{x}_0 = c_1\\mathbf{v}_1 + c_2\\mathbf{v}_2$\n4. Solve for $c_i$: $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = c_1\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + c_2\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n5. Get $c_1 = \\frac{1}{2}$, $c_2 = \\frac{1}{2}$\n6. Solution: $\\mathbf{x}_k = \\frac{1}{2}(3^k)\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\frac{1}{2}(1^k)\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n:::\n\n### Problem 3: Determining if λ is an Eigenvalue\n\n::: {.callout-note collapse=\"true\"}\n#### Problem\nDetermine if $\\lambda = 2$ is an eigenvalue of $A = \\begin{bmatrix} 3 & 1 \\\\ -1 & 5 \\end{bmatrix}$\n\n#### Solution\nStep 1: Form $A - 2I$\n$$A - 2I = \\begin{bmatrix} 1 & 1 \\\\ -1 & 3 \\end{bmatrix}$$\n\nStep 2: Calculate $\\det(A - 2I)$\n$\\det(A - 2I) = (1)(3) - (1)(-1) = 3 + 1 = 4$\n\nStep 3: Conclusion\nSince $\\det(A - 2I) \\neq 0$, $\\lambda = 2$ is not an eigenvalue of $A$\n\nAlternative method:\n1. Find characteristic equation: $\\det(A - \\lambda I) = 0$\n2. $(3-\\lambda)(5-\\lambda) - (-1)(1) = 0$\n3. $\\lambda^2 - 8\\lambda + 14 = 0$\n4. $\\lambda = 4 \\pm \\sqrt{2}$\nTherefore, 2 is not an eigenvalue\n:::\n\n## Common Mistakes to Avoid\n\n1. Not checking if eigenvector is nonzero\n2. Assuming eigenvalues must be on the main diagonal (only true for triangular matrices)\n3. Forgetting that eigenvectors corresponding to the same eigenvalue might be linearly dependent\n4. Not verifying that λ is a real number when working in real vector spaces\n5. Confusing eigenspace with the span of eigenvectors\n\n## Additional Resources\n\n- [3Blue1Brown - Essence of Linear Algebra (YouTube)](https://www.youtube.com/watch?v=kjBOesZCoqc)\n- Gilbert Strang's Linear Algebra Lectures (MIT OpenCourseWare)\n- \"Introduction to Probability\" by Bertsekas and Tsitsiklis\n- \"Matrix Analysis\" by Horn and Johnson"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":{"source":false,"toggle":true,"caption":"See code"},"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"html-math-method":"katex","output-file":"eigenvalues_eigenvectors.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":{"light":"lightly","dark":"darkly"},"page-layout":"full","toc-location":"right","code-summary":"Show the code","code-copy":"hover","title":"Eigenvalues and Eigenvectors in Linear Algebra"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}